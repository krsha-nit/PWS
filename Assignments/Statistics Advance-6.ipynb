{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7191be9",
   "metadata": {},
   "source": [
    "#### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "    Ans. Assumptions of ANOVA:\n",
    "    Independence: Observations within each group must be independent of each other. In other words, the data points in one group should not be influenced by or related to the data points in another group.\n",
    "    Normality: The data within each group should be approximately normally distributed. This assumption is more critical when the sample sizes are small, as ANOVA is robust to violations of normality with larger sample sizes.\n",
    "    Homogeneity of variance (Homoscedasticity): The variability (variance) of the data should be roughly the same across all groups. This means that the spread of the data points should be similar for each group.\n",
    "    Random Sampling: The data should be collected through a random sampling process, ensuring that the sample is representative of the population.\n",
    "    \n",
    "    Examples of Violations:\n",
    "    Non-Independence: If the observations within one group are influenced by or related to observations in another group, it violates the independence assumption. For instance, if the same individuals are included in multiple groups or if there is some form of dependency between groups, it can lead to invalid ANOVA results.\n",
    "    Non-Normality: If the data within each group significantly deviates from a normal distribution, it can affect the validity of the ANOVA results. This can be checked using graphical methods (e.g., QQ-plots) or statistical tests (e.g., Shapiro-Wilk test).\n",
    "    Non-Homogeneity of Variance: Unequal variances across the groups can lead to biased results. Violation of this assumption can be assessed using statistical tests (e.g., Levene's test) or visual inspection of variance plots.\n",
    "    Non-Random Sampling: If the data is not collected through a random sampling process, the ANOVA results may not be generalizable to the target population. This can introduce bias and limit the external validity of the findings.\n",
    "\n",
    "\n",
    "#### Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "    Ans.One-Way ANOVA: This type of ANOVA is used when there is a single categorical independent variable (with two or more levels/groups) and a continuous dependent variable. It determines if there are any statistically significant differences between the means of the groups.\n",
    "\n",
    "    Two-Way ANOVA: This type of ANOVA is used when there are two categorical independent variables (factors) and one continuous dependent variable. It examines the main effects of each factor and their interaction effect on the dependent variable.\n",
    "\n",
    "    Three-Way ANOVA (and higher): This type of ANOVA extends the concept of two-way ANOVA to situations with three or more categorical independent variables. It is used when there are multiple factors, and researchers want to examine their individual and combined effects on the dependent variable.\n",
    "\n",
    "#### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "    Ans. The partitioning of variance in ANOVA involves breaking down the total variability in the data into different components attributed to specific sources. For a one-way ANOVA, the total variance (SST) is divided into two main components:\n",
    "\n",
    "    Total Sum of Squares (SST): SST represents the total variability in the dependent variable and is calculated as the sum of squared differences between each data point and the overall mean of all data points.\n",
    "\n",
    "    Explained Sum of Squares (SSE): SSE, also known as the \"between-group\" variability, measures the variation between the group means and the overall mean. It quantifies how much of the total variance can be attributed to the effect of the independent variable.\n",
    "\n",
    "    Residual Sum of Squares (SSR): SSR, also called the \"within-group\" variability, measures the variation within each group. It represents the differences between individual data points and their respective group means.\n",
    "\n",
    "    The partitioning is essential because it helps researchers understand the relative contributions of the independent variable (treatment effect) and random variability (error) to the overall variance in the dependent variable. By comparing SSE to SSR, ANOVA can determine whether the observed differences between group means are statistically significant or simply due to chance.\n",
    "\n",
    "#### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "    Ans. To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can follow these steps:\n",
    "\n",
    "    Compute the overall mean (grand mean) of the data.\n",
    "    Calculate the sum of squared differences between each data point and the overall mean to get the Total Sum of Squares (SST).\n",
    "    Calculate the sum of squared differences between each group mean and the overall mean to get the Explained Sum of Squares (SSE).\n",
    "    Calculate the sum of squared differences between each data point and its respective group mean to get the Residual Sum of Squares (SSR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3211b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 501.7333333333333\n",
      "Explained Sum of Squares (SSE): 464.5333333333333\n",
      "Residual Sum of Squares (SSR): 37.19999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data for three groups (replace these with your own data)\n",
    "group_a = [10, 12, 15, 14, 11]\n",
    "group_b = [18, 20, 22, 19, 21]\n",
    "group_c = [25, 28, 24, 27, 26]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group_a, group_b, group_c])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group_a = np.mean(group_a)\n",
    "mean_group_b = np.mean(group_b)\n",
    "mean_group_c = np.mean(group_c)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = np.sum((mean_group_a - overall_mean)**2) * len(group_a) + \\\n",
    "      np.sum((mean_group_b - overall_mean)**2) * len(group_b) + \\\n",
    "      np.sum((mean_group_c - overall_mean)**2) * len(group_c)\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a2803",
   "metadata": {},
   "source": [
    "#### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c742a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 144.4000000000001\n",
      "Main Effect B: 2.016666666666664\n",
      "Interaction Effect: 0.01666666666666798\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data for a two-way ANOVA (replace these with your own data)\n",
    "data = {\n",
    "    'A': ['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B'],\n",
    "    'B': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'Y': [10, 12, 15, 14, 11, 18, 20, 22, 19, 21]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Y' column to numeric (optional, depending on your data)\n",
    "df['Y'] = pd.to_numeric(df['Y'])\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Y ~ C(A) + C(B) + C(A):C(B)'  # C() indicates categorical variables and ':' represents interaction\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effect from the ANOVA table\n",
    "main_effect_A = anova_table.loc['C(A)', 'mean_sq']\n",
    "main_effect_B = anova_table.loc['C(B)', 'mean_sq']\n",
    "interaction_effect = anova_table.loc['C(A):C(B)', 'mean_sq']\n",
    "\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d91293",
   "metadata": {},
   "source": [
    "#### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "    Ans.In a one-way ANOVA, the obtained F-statistic and p-value are used to determine whether there are significant differences between the groups (treatment levels) with respect to the dependent variable.\n",
    "\n",
    "    F-statistic: The F-statistic measures the ratio of the variance between the group means to the variance within the groups. In this case, the F-statistic is 5.23.\n",
    "\n",
    "    p-value: The p-value represents the probability of obtaining the observed results (or more extreme results) if there were no true differences between the group means. In this case, the p-value is 0.02.\n",
    "\n",
    "    Interpretation:\n",
    "    Since the p-value (0.02) is less than the commonly chosen significance level of 0.05, we reject the null hypothesis. The null hypothesis in ANOVA assumes that there are no significant differences between the group means. Thus, we can conclude that there are significant differences between at least some of the groups.\n",
    "\n",
    "    However, the ANOVA does not tell us exactly which groups are different from each other. To identify the specific differences between groups, further post-hoc tests (e.g., Tukey's test) can be conducted.\n",
    "\n",
    "#### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "    Ans. In a repeated measures ANOVA, where the same participants are measured multiple times under different conditions, handling missing data can be crucial for obtaining accurate results.\n",
    "\n",
    "    Methods for Handling Missing Data:\n",
    "\n",
    "    Complete Case Analysis (Listwise Deletion): In this method, any participant with missing data on any variable is excluded from the analysis. While it is straightforward, it may lead to a loss of statistical power and potential bias.\n",
    "\n",
    "    Mean Imputation: Missing values are replaced with the mean value of the observed data. This can distort the variability and relationships in the data.\n",
    "\n",
    "    Multiple Imputation: This method creates multiple plausible imputed datasets based on the observed data's distribution. The analysis is performed on each imputed dataset, and the results are combined. It is more robust than mean imputation but requires additional computational resources.\n",
    "\n",
    "    Maximum Likelihood Estimation: This method estimates missing values based on the likelihood function, considering the relationship between variables. It is considered a principled approach and can provide unbiased estimates.\n",
    "\n",
    "    Potential Consequences of Different Methods:\n",
    "    Using inappropriate missing data handling methods can lead to biased estimates, reduced statistical power, and incorrect conclusions. Complete case analysis can decrease the sample size, leading to a loss of information. Mean imputation can affect the data distribution and correlations. Multiple imputation and maximum likelihood estimation are generally preferred when data are missing at random, as they provide more accurate estimates and appropriate standard errors.\n",
    "\n",
    "\n",
    "#### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "    Ans. Post-hoc tests are used to compare multiple groups in ANOVA when the overall ANOVA result is significant. Some common post-hoc tests include:\n",
    "\n",
    "    Tukey's Honestly Significant Difference (HSD): Tukey's test is used to identify differences between all pairs of groups. It controls the familywise error rate and is appropriate when the number of group comparisons is relatively small.\n",
    "\n",
    "    Bonferroni Correction: This method adjusts the significance level for multiple comparisons to avoid inflating the overall Type I error rate. It is more conservative than Tukey's test and appropriate when the number of comparisons is large.\n",
    "\n",
    "    Scheffe's Test: Scheffe's test is conservative but suitable for complex comparisons, including combinations of linear and non-linear contrasts.\n",
    "\n",
    "    Dunnett's Test: Dunnett's test is used when comparing several treatment groups to a control group, and it controls the Type I error rate.\n",
    "\n",
    "\n",
    "#### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c56f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 18.95238095238094\n",
      "p-value: 0.0001933016445130483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for weight loss for each diet (replace these with your own data)\n",
    "diet_A = [5, 6, 7, 6, 5]\n",
    "diet_B = [4, 3, 2, 3, 4]\n",
    "diet_C = [2, 3, 4, 3, 2]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create a group labels array\n",
    "groups = ['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Weight Loss': data, 'Diet': groups})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856d864",
   "metadata": {},
   "source": [
    "    Interpretation:\n",
    "    In this example, the one-way ANOVA yields an F-statistic of F_statistic and a p-value of p_value. Since the p-value (p_value) is less than 0.05 (assuming a significance level of 0.05), we can conclude that there are significant differences in the mean weight loss between the three diets (A, B, and C). Further post-hoc tests can be performed to identify which diets are significantly different from each other.\n",
    "\n",
    "\n",
    "#### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4cc01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                sum_sq    df         F    PR(>F)\n",
      "C(Software)                   2.600000   2.0  0.022414  0.977856\n",
      "C(Experience)               425.633333   1.0  7.338506  0.012252\n",
      "C(Software):C(Experience)    28.066667   2.0  0.241954  0.786984\n",
      "Residual                   1392.000000  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data for task completion time (replace these with your own data)\n",
    "data = {\n",
    "    'Software': ['A', 'B', 'C'] * 10,\n",
    "    'Experience': ['Novice'] * 15 + ['Experienced'] * 15,\n",
    "    'Time': [25, 30, 27, 32, 28, 34, 30, 33, 31, 35,\n",
    "             22, 20, 24, 19, 23, 18, 26, 21, 29, 27,\n",
    "             40, 38, 42, 36, 41, 39, 37, 44, 43, 45]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def7d0b",
   "metadata": {},
   "source": [
    "    Interpretation:\n",
    "    In this two-way ANOVA, we are analyzing the effects of two factors: 'Software' (with levels A, B, and C) and 'Experience' (with levels Novice and Experienced) on the task completion time.\n",
    "\n",
    "    Main Effects:\n",
    "    The 'Software' factor's p-value indicates whether there are significant differences in task completion time between the three software programs (A, B, and C). If the p-value for 'Software' is less than the chosen significance level (e.g., 0.05), it suggests that at least one software program significantly affects task completion time.\n",
    "    The 'Experience' factor's p-value indicates whether there are significant differences in task completion time between novice and experienced users. If the p-value for 'Experience' is less than the significance level, it suggests that the level of experience significantly influences task completion time.\n",
    "\n",
    "    Interaction Effect:\n",
    "    The interaction effect between 'Software' and 'Experience' examines whether the effect of one factor (e.g., 'Software') on task completion time depends on the level of the other factor (e.g., 'Experience'). If the p-value for the interaction term is significant (p < 0.05), it indicates that the effect of software on task completion time is different for novice and experienced users, and there is an interaction between these two factors.\n",
    "    \n",
    "    Overall, the two-way ANOVA helps us understand how the software program and user experience level interact to influence task completion time. The interpretation of the results should be based on the specific p-values and the chosen significance level. If significant effects are found, further post-hoc tests (e.g., Tukey's test) can be conducted to identify which software program or user experience level differs significantly from others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c78db9",
   "metadata": {},
   "source": [
    "#### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "695428ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -2.835436868147591\n",
      "p-value: 0.010969952273298564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for test scores (replace these with your own data)\n",
    "control_group = [80, 85, 78, 90, 88, 82, 75, 84, 92, 81]  # Continue with 100 control scores\n",
    "experimental_group = [88, 90, 82, 95, 87, 94, 86, 89, 93, 91]  # Continue with 100 experimental scores\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955ae0",
   "metadata": {},
   "source": [
    "    Interpretation:\n",
    "    The two-sample t-test yields a t-statistic of t_statistic and a p-value of p_value. If the p-value is less than the chosen significance level (e.g., 0.05), it indicates a significant difference in test scores between the two groups.\n",
    "\n",
    "    If the result is significant, you can conduct post-hoc tests to determine which group(s) differ significantly from each other. A common post-hoc test for comparing two independent groups is the Tukey-Kramer test or Bonferroni correction for pairwise comparisons.\n",
    "\n",
    "#### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c3b7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   df         sum_sq      mean_sq         F    PR(>F)\n",
      "C(Store)          2.0    8418.688889  4209.344444  0.496990  0.610841\n",
      "C(Day)           29.0  195196.381988  6730.909724  0.794707  0.747570\n",
      "C(Store):C(Day)  58.0  470311.918012  8108.826173  0.957395  0.565521\n",
      "Residual         60.0  508180.666667  8469.677778       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data for daily sales (replace these with your own data)\n",
    "data = {\n",
    "    'Day': np.repeat(np.arange(1, 31), 3),\n",
    "    'Store': ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30,\n",
    "    'Sales': np.random.randint(900,1200,90)  # Continue with 30 daily sales for each store\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "formula = 'Sales ~ C(Store) + C(Day) + C(Store):C(Day)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303e5b",
   "metadata": {},
   "source": [
    "    Interpretation:\n",
    "    The repeated measures ANOVA provides F-statistics and p-values for the main effect of 'Store,' the main effect of 'Day,' and the interaction effect between 'Store' and 'Day.'\n",
    "\n",
    "    If the p-value for the main effect of 'Store' is less than the chosen significance level (e.g., 0.05), it indicates a significant difference in average daily sales between the three stores.\n",
    "\n",
    "    If the result is significant, you can conduct post-hoc tests (e.g., Tukey's test) to determine which store(s) differ significantly from each other in terms of average daily sales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
